{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2a30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0963c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc9ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7193679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9892f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    vgg16 = tf.keras.applications.VGG16(\n",
    "    input_shape = input_shape,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\")\n",
    "    vgg16.trainable=False\n",
    "    \n",
    "    flatten_layer = tf.keras.layers.Flatten()\n",
    "    dense_layer = tf.keras.layers.Dense(256,activation='relu')\n",
    "    dropout_1 = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
    "    batch_1 = tf.keras.layers.BatchNormalization()\n",
    "    dense_layer_2 = tf.keras.layers.Dense(256,activation='relu')\n",
    "    dropout_2 = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
    "    batch_2 = tf.keras.layers.BatchNormalization()\n",
    "    dense_layer_3 = tf.keras.layers.Dense(256)\n",
    "                                          \n",
    "    vgg16_model = tf.keras.Sequential([\n",
    "      vgg16,\n",
    "      flatten_layer,\n",
    "      dense_layer,\n",
    "      dropout_1,\n",
    "      batch_1,\n",
    "      dense_layer_2,\n",
    "      dropout_2,\n",
    "      batch_2,\n",
    "      dense_layer_3\n",
    "    ])\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = vgg16_model(left_input)\n",
    "    encoded_r = vgg16_model(right_input)\n",
    "        \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29be2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 256)          16028224    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,028,481\n",
      "Trainable params: 1,312,769\n",
      "Non-trainable params: 14,715,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((96, 96, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ec0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.00001)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dd68571",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(r\"C:\\Users\\sriba\\Documents\\Python Scripts\\Siamese\\OneShotDocClassification\\weights_vgg\",\"weights.14000.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3866b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = image.reshape(1,96,96,3)\n",
    "    image = image[...,::-1]\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d1117d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 256)          16028224    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,028,481\n",
      "Trainable params: 1,312,769\n",
      "Non-trainable params: 14,715,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d41a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c7c954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f585f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r\"C:\\Users\\sriba\\Documents\\Python Scripts\\Siamese\\OneShotDocClassification\\val_data\\new\"\n",
    "train = os.path.join(base, \"train\")\n",
    "test = os.path.join(base, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d208b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "for category in os.listdir(train):\n",
    "    category_path = os.path.join(train, category)\n",
    "    data = []\n",
    "    for file in os.listdir(category_path):\n",
    "        img = read_img(os.path.join(category_path, file))\n",
    "        data.append(img)\n",
    "    data_dic[category] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244c2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ADVE\n",
      "5\n",
      "ADVE 0.9362271\n",
      "ADVE 0.9993293\n",
      "ADVE 0.9927799\n",
      "ADVE 0.9909651\n",
      "ADVE 0.9920372\n",
      "Folder Email\n",
      "4\n",
      "Email 0.91695553\n",
      "Email 0.9547016\n",
      "Email 0.9512208\n",
      "Email 0.9713198\n",
      "Folder Letter\n",
      "4\n",
      "letter 0.05429149\n",
      "letter 0.7504741\n",
      "ADVE 0.33699843\n",
      "letter 0.12653182\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "pair = []\n",
    "for category in os.listdir(test):\n",
    "    print(\"Folder\", category)\n",
    "    category_path = os.path.join(test, category)\n",
    "    print(len(os.listdir(category_path)))\n",
    "    for file in os.listdir(category_path):\n",
    "        img = read_img(os.path.join(category_path, file))\n",
    "        cat_result = {}\n",
    "        for key in data_dic:\n",
    "            #print(key)\n",
    "            predict_result = []\n",
    "            train_data = data_dic[key]\n",
    "            for data in train_data:\n",
    "                result = model.predict([data, img])\n",
    "                predict_result.append(result[0][0])\n",
    "            #print(result)\n",
    "            cat_result[key] = max(predict_result)\n",
    "            predicted = max(cat_result.items(), key=operator.itemgetter(1))[0]\n",
    "        print(predicted, cat_result[predicted])\n",
    "        #print(cat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1f7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
